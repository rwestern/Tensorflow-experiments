{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import plotly\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pandas.read_csv('C:/local datasets/RAD/rad response level 20180716.csv',\n",
    "                                 parse_dates = ['EVENT_DATE', 'DATE_CALLSTART', 'FIRST_NFD_DT',\"CLI_DATE\",\"DATE_ACCEPTED\",\"DATE_DISPATCH_FD\",\"DATE_DISPATCH_FDA\",\"DATE_DISPATCH_FA\",\"DATE_ARRIVED_FD\",\"DATE_ARRIVED_FDA\",\"DATE_ARRIVED_FA\",\"DATE_FIRST_P0\",\"DATE_FIRST_C1\",\"DATE_FIRST_C2\",\"DATE_FIRST_C3\"],\n",
    "                                 infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_DATE_WID                           int64\n",
      "EVENT_DATE                      datetime64[ns]\n",
      "COMMONEVENTID                            int64\n",
      "COMM_EVENT_WID                           int64\n",
      "N_EVENT_NUMBERS                          int64\n",
      "REFCOM_DISPATCH                         object\n",
      "GEO_UCL                                 object\n",
      "GEO_CATCHMENT                           object\n",
      "GEO_REGION                              object\n",
      "GEO_LONGITUDE                          float64\n",
      "GEO_LATITUDE                           float64\n",
      "N_EVENT_TYPES                            int64\n",
      "FIRST_EVENT_TYPE                        object\n",
      "LAST_EVENT_TYPE                         object\n",
      "FINAL_EVENT_TYPE_CARD                   object\n",
      "FIRST_PRIORITY_CODE                      int64\n",
      "LAST_PRIORITY_CODE                       int64\n",
      "MIN_PRIORITY_CODE                        int64\n",
      "N_DISPATCHED                             int64\n",
      "N_ARRIVED                                int64\n",
      "DATE_CALLSTART                  datetime64[ns]\n",
      "FIRST_NFD_DT                    datetime64[ns]\n",
      "CLI_DATE                        datetime64[ns]\n",
      "DATE_ACCEPTED                   datetime64[ns]\n",
      "DATE_DISPATCH_FD                datetime64[ns]\n",
      "DATE_DISPATCH_FDA               datetime64[ns]\n",
      "DATE_DISPATCH_FA                datetime64[ns]\n",
      "DATE_ARRIVED_FD                 datetime64[ns]\n",
      "DATE_ARRIVED_FDA                datetime64[ns]\n",
      "DATE_ARRIVED_FA                 datetime64[ns]\n",
      "                                     ...      \n",
      "HIERARCHY_TM_NAME                       object\n",
      "HIERARCHY_GM_NAME                       object\n",
      "HIERARCHY_RD_NAME                       object\n",
      "TEAM_DEPARTMENT                         object\n",
      "PART_DESC                               object\n",
      "REGION_NAME                             object\n",
      "GROUP_NAME                              object\n",
      "BRANCH_NAME                             object\n",
      "TEAM_NAME                               object\n",
      "TEAM_CATEGORY                           object\n",
      "TEAM_TYPE                               object\n",
      "DISPATCH_WARNING                        object\n",
      "DISPATCH_FROM_STATUS                    object\n",
      "EMG_FIRST_ARRIVED_FINCAD_FLG            object\n",
      "FIRST_DISPATCHED_FINCAD_FLG             object\n",
      "DISPATCH_ORDER                           int64\n",
      "ARRIVAL_ORDER                            int64\n",
      "OBIEE_ACTIVE_CASE_FLAG                  object\n",
      "DATE_DISPATCH_FINCAD                    object\n",
      "DATE_AT_LOCATION_FINCAD                 object\n",
      "CASE_ACTIV_TIME_FINCAD                   int64\n",
      "RESP_ACTIV_TIME_FINCAD                 float64\n",
      "RESP_CASE_TIME_FINCAD                  float64\n",
      "REFLEX_TIME_FINCAD                     float64\n",
      "TURNOUT_TIME_FINCAD                    float64\n",
      "TRAVEL_TIME_FINCAD                     float64\n",
      "RESPONSE_TIME_FINCAD                   float64\n",
      "UNIT_RESPONSE_DISTANCE                 float64\n",
      "UNIT_RESPONSE_DISTANCE_AVL             float64\n",
      "RESPONSE_DISTANCE_OPTIMUM              float64\n",
      "Length: 113, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(responses.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.dropna(subset = ['DATE_CALLSTART'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ri072731\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "responses['DATE_CALLSTARThour'] = responses.DATE_CALLSTART.dt.hour.astype(int)\n",
    "responses['DATE_CALLSTARTmonth'] = responses.DATE_CALLSTART.dt.month.astype(int)\n",
    "responses['DATE_CALLSTARTweekday'] = responses.DATE_CALLSTART.dt.weekday.astype(int)\n",
    "responses.GEO_CATCHMENT = responses.GEO_CATCHMENT.fillna('Other')\n",
    "responses.GEO_REGION = responses.GEO_REGION.fillna('Other')\n",
    "\n",
    "responses['training'] = responses.DATE_CALLSTART < responses.DATE_CALLSTART.max() - timedelta(days = 30)\n",
    "responses['weight'] = responses.REFERRED_TO_DM.apply(lambda x: 1 if x == 'Y' else 2)\n",
    "responses.weight[responses.training] = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(batch_sz, x, y=None, shuffle=False, shuffle_buffer_size=1000):\n",
    "    \"\"\"Create a slice Dataset from a pandas DataFrame and labels\"\"\"\n",
    "\n",
    "    def input_fn():\n",
    "        if y is not None:\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
    "        else:\n",
    "            dataset = tf.data.Dataset.from_tensor_slices(dict(x))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(shuffle_buffer_size).batch(batch_sz).repeat()\n",
    "        else:\n",
    "            dataset = dataset.batch(batch_sz)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    return input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_CALLSTARThour = tf.feature_column.categorical_column_with_identity(key='DATE_CALLSTARThour', num_buckets = 25)\n",
    "DATE_CALLSTARTmonth = tf.feature_column.categorical_column_with_identity(key='DATE_CALLSTARTmonth', num_buckets = 13)\n",
    "DATE_CALLSTARTweekday = tf.feature_column.categorical_column_with_identity(key='DATE_CALLSTARTweekday', num_buckets = 8)\n",
    "GEO_CATCHMENT = tf.feature_column.categorical_column_with_hash_bucket(key=\"GEO_CATCHMENT\", hash_bucket_size=50)\n",
    "FIRST_EVENT_TYPE = tf.feature_column.categorical_column_with_hash_bucket(key=\"FIRST_EVENT_TYPE\", hash_bucket_size=50)\n",
    "REFCOM_DISPATCH = tf.feature_column.categorical_column_with_vocabulary_list(key=\"REFCOM_DISPATCH\", vocabulary_list = ['Y', 'N'])\n",
    "GEO_REGION = tf.feature_column.categorical_column_with_vocabulary_list(key=\"REFCOM_DISPATCH\", vocabulary_list = responses.GEO_REGION.unique())\n",
    "weight = tf.feature_column.numeric_column(key='weight')\n",
    "\n",
    "column_names = {\n",
    "    'DATE_CALLSTARThour',\n",
    "    'DATE_CALLSTARTmonth',\n",
    "    'DATE_CALLSTARTweekday',\n",
    "    'GEO_CATCHMENT',\n",
    "    'FIRST_EVENT_TYPE',\n",
    "    'REFCOM_DISPATCH',\n",
    "    'GEO_REGION',\n",
    "    'weight'\n",
    "}\n",
    "feature_columns = [\n",
    "    tf.feature_column.indicator_column(tf.feature_column.crossed_column([DATE_CALLSTARThour, DATE_CALLSTARTweekday], hash_bucket_size=50)),\n",
    "    #tf.feature_column.indicator_column(tf.feature_column.crossed_column([GEO_REGION, DATE_CALLSTARTmonth], hash_bucket_size=50)),\n",
    "    tf.feature_column.indicator_column(GEO_CATCHMENT),\n",
    "    tf.feature_column.indicator_column(FIRST_EVENT_TYPE),\n",
    "    tf.feature_column.indicator_column(REFCOM_DISPATCH),\n",
    "    tf.feature_column.indicator_column(DATE_CALLSTARThour),\n",
    "    tf.feature_column.indicator_column(DATE_CALLSTARTmonth),\n",
    "    tf.feature_column.indicator_column(DATE_CALLSTARTweekday),\n",
    "    weight\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "# Provide the training input dataset.\n",
    "train_set = responses[responses.training == True]\n",
    "test_set = responses[responses.training == False]\n",
    "\n",
    "train_x = train_set[list(column_names)]\n",
    "train_y = train_set['REFERRED_TO_DM'] == 'Y'\n",
    "\n",
    "test_x = test_set[list(column_names)]\n",
    "test_y = test_set['REFERRED_TO_DM'] == 'Y'\n",
    "\n",
    "train_input_fn = make_dataset(batch_size, train_x, train_y, True, 1000)\n",
    "\n",
    "test_input_fn = make_dataset(batch_size, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ri072731\\AppData\\Local\\Temp\\tmpkutnfzpw\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ri072731\\\\AppData\\\\Local\\\\Temp\\\\tmpkutnfzpw', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002800283E550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier(hidden_units=[1024, 512, 256],\n",
    "                                   feature_columns=feature_columns,\n",
    "                                   weight_column = 'weight',\n",
    "                                   optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "                                       learning_rate=0.1,\n",
    "                                       l1_regularization_strength=0.001,\n",
    "                                       l2_regularization_strength=0.001\n",
    "                                   ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\ri072731\\AppData\\Local\\Temp\\tmpkutnfzpw\\model.ckpt.\n",
      "INFO:tensorflow:loss = 100.940384, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 100 into C:\\Users\\ri072731\\AppData\\Local\\Temp\\tmpkutnfzpw\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 43.31354.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hooks = [tf.train.SummarySaverHook(scaffold=tf.train.Scaffold(summary_op=tf.summary.merge_all()),\n",
    "          save_steps = 5,\n",
    "          output_dir='/tmp/tf'\n",
    "          )]\n",
    "classifier = model.train(input_fn=train_input_fn, steps=100, hooks = hooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-27-02:46:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ri072731\\AppData\\Local\\Temp\\tmpkutnfzpw\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-27-02:46:46\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9613662, accuracy_baseline = 0.9623504, auc = 0.5030465, auc_precision_recall = 0.03806567, average_loss = 0.17974292, global_step = 100, label/mean = 0.037649564, loss = 34.63843, precision = 0.031847134, prediction/mean = 0.058173094, recall = 0.000889205\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: C:\\Users\\ri072731\\AppData\\Local\\Temp\\tmpkutnfzpw\\model.ckpt-100\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9613662, 'accuracy_baseline': 0.9623504, 'auc': 0.5030465, 'auc_precision_recall': 0.03806567, 'average_loss': 0.17974292, 'label/mean': 0.037649564, 'loss': 34.63843, 'precision': 0.031847134, 'prediction/mean': 0.058173094, 'recall': 0.000889205, 'global_step': 100}\n"
     ]
    }
   ],
   "source": [
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ri072731\\AppData\\Local\\Temp\\tmpkutnfzpw\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions=list(classifier.predict(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_y = [p['class_ids'][0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71788    76]\n",
      " [ 5618     5]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session():\n",
    "    print(tf.Tensor.eval(tf.confusion_matrix(labels=list(test_y), predictions=out_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
